# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json

x-common-env: &common-env
  TZ: ${TZ:-America/Chicago} # Your Timezone
  PUID: ${PUID:-1002}
  PGID: ${PGID:-988}
  UMASK: ${UMASK:-002}

x-common-uidgid: &common-uidgid
  user: ${PUID:-1002}:${PGID:-988}

x-resource-limits: &resource-limits
  cpu_shares: 1024
  labels:
    autoheal: "true"

x-common-deploy: &common-deploy
  restart_policy:
    condition: on-failure
    delay: 5s
    window: 120s
  labels:
    autoheal: "true"
    swarm.autoscaler: "true"

x-swarm-resource-limits: &swarm-resource-limits
  resources:
    limits:
      cpus: "0.10"
      memory: 512M

x-swarm-preferences-worker-priority: &swarm-preferences-worker-priority
  placement:
    preferences:
      - spread: node.labels.worker_priority

x-swarm-constraints-worker-only: &swarm-constraints-worker-only
  placement:
    constraints:
      - node.role == worker

x-swarm-constraints-manager-only: &swarm-constraints-manager-only
  placement:
    constraints:
      - node.role == manager

services:
  flaresolverr:
    # ðŸ”¹ðŸ”¹ Flaresolverr ðŸ”¹ðŸ”¹  # https://github.com/flaresolverr/flaresolverr
    image: ghcr.io/flaresolverr/flaresolverr
    container_name: flaresolverr
    <<: *resource-limits
    network_mode: service:gluetun
    security_opt:
      - no-new-privileges:true
    environment:
      <<: *common-env
      CAPTCHA_SOLVER: ${FLARESOLVERR_CAPTCHA_SOLVER:-none}
      LOG_HTML: ${FLARESOLVERR_LOG_HTML:-false}
      LOG_LEVEL: ${FLARESOLVERR_LOG_LEVEL:-info}
    labels:
      homepage.group: Utilities
      homepage.name: FlareSolverr
      homepage.icon: flaresolverr.png
      homepage.href: https://flaresolverr.$DOMAIN/
      homepage.description: Proxy server to bypass Cloudflare protection, enabling access to websites that are protected by anti-bot measures.
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
    restart: always

  meilisearch:
    # ðŸ”¹ðŸ”¹ Meilisearch ðŸ”¹ðŸ”¹
    image: getmeili/meilisearch
    container_name: meilisearch
    hostname: meilisearch
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - traefik_public
    environment:
      <<: *common-env
      http_proxy:
      https_proxy:
      MEILI_DB_PATH: ${MEILI_DB_PATH:-/data.ms}
      MEILI_ENV: ${MEILI_ENV:-development}
      MEILI_LOG_LEVEL: ${MEILI_LOG_LEVEL:-info}
      MEILI_MASTER_KEY: $MEILI_MASTER_KEY
      MEILI_NO_ANALYTICS: ${MEILI_NO_ANALYTICS:-true}
    ports:
      - ${MEILI_PORT:-7700}:7700
    volumes:
      - ${CONFIG_PATH:-./volumes}/meilisearch:/data.ms
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
    healthcheck:
      test: curl -fSs http://localhost:7700 > /dev/null || exit 1
      start_period: 20s
      timeout: 5s
      interval: 5s
    restart: always

  playwright:
    # ðŸ”¹ðŸ”¹ Playwright ðŸ”¹ðŸ”¹
    # Fast and reliable end-to-end testing for modern web apps
    image: mcr.microsoft.com/playwright
    container_name: playwright
    hostname: playwright
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - infranet
    ports:
      - ${PLAYWRIGHT_PORT:-2999}:${PLAYWRIGHT_PORT:-2999}
    environment:
      <<: *common-env
      BLOCK_MEDIA: ${PLAYWRIGHT_BLOCK_MEDIA:-false}
      DEBUG: ${PLAYWRIGHT_DEBUG:-false}
      LOG_LEVEL: ${PLAYWRIGHT_LOG_LEVEL:-info}
      PORT: ${PLAYWRIGHT_PORT:-2999}
      PROXY_PASSWORD: $PLAYWRIGHT_PROXY_PASSWORD
#      PROXY_SERVER: $PLAYWRIGHT_PROXY_SERVER
      PROXY_USERNAME: $PLAYWRIGHT_PROXY_USERNAME
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
    restart: always

  prometheus:
    # ðŸ”¹ðŸ”¹ Prometheus ðŸ”¹ðŸ”¹  https://github.com/prometheus/prometheus
    image: prom/prometheus
    container_name: prometheus
    hostname: prometheus
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - traefik_public
    ports:
      - ${PROMETHEUS_PORT:-9090}:9090
    volumes:
      - ${CONFIG_PATH:-./volumes}/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: [
        "--config.file=/etc/prometheus/prometheus.yml", # Specifies the path to the Prometheus configuration file
        "--storage.tsdb.retention.size=1GB", # Sets the maximum size of the time series database to 1GB
        "--web.console.libraries=/etc/prometheus/console_libraries", # Path to console libraries for the web UI
        "--web.console.templates=/etc/prometheus/consoles", # Path to console templates for the web UI
        "--web.enable-lifecycle", # Enables lifecycle management for the web interface (e.g., for graceful shutdown)
      ]
    labels:
      homepage.group: Server Monitoring
      homepage.name: Prometheus Monitoring
      homepage.icon: prometheus.png
      homepage.href: https://prometheus.$DOMAIN
      homepage.description: Monitors your server's performance and resource usage, providing detailed metrics and alerts to help you maintain system health.
    environment:
      <<: *common-env
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
      mode: replicated # Deploys the service in replicated mode
      replicas: 1 # Specifies that only one replica of the service should be running
      placement:
        constraints:
          - node.role == manager # Ensures that the service runs only on manager nodes in a Swarm
      resources:
        limits:
          cpus: "0.50" # Sets a limit of 0.5 CPU for the service
          memory: 512M # Sets a limit of 1024 MB of memory for the service
        reservations:
          cpus: "0.50" # Reserves 0.5 CPU for the service
          memory: 128M # Reserves 128 MB of memory for the service
    restart: always

  redis:
    #image: redis:alpine
    image: docker.io/library/redis:alpine
    container_name: redis
    hostname: redis
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - traefik_public
    ports:
      - ${REDIS_PORT:-6379}:6379
    security_opt:
      - no-new-privileges:true
    volumes:
      - ${CONFIG_PATH:-./volumes}/redis:/data
      - ${CONFIG_PATH:-./volumes}/redis/etc/sysctl.conf:/etc/sysctl.conf
    command: --save 60 1 --loglevel warning
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 3s
    restart: always

  searxng:
    # ðŸ”¹ðŸ”¹ SearxNG ðŸ”¹ðŸ”¹  # https://hub.docker.com/r/searxng/searxng
    # SearxNG is a privacy-respecting, hackable, open-source metasearch engine.
    image: docker.io/searxng/searxng
    container_name: searxng
    hostname: searxng
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - infranet
    ports:
      - ${SEARXNG_PORT:-8077}:8080
    volumes:
      - ${CONFIG_PATH:-./volumes}/searxng:/etc/searxng
    environment:
      <<: *common-env
      SEARXNG_BASE_URL: http://localhost:${SEARXNG_PORT:-8077}
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 2
