# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json
# TODO: com.docker.network.bridge.inhibit_ipv4=true


volumes:
  warp-config-data:



# reminder: everything in docker-compose.yml's `configs:` section must have dollar signs ($) escaped with another dollar sign ($$).
# Single dollar sign specifies that we're expecting docker to resolve the variable itself at deploy time (e.g. when `docker compose up` is ran).
# Double dollar sign specifies a literal dollar sign in the configuration content.
configs:
  warp-nat-setup.sh:
    content: |
      #!/bin/bash
      set -xe

      # Defaults (configurable via env)
      DOCKER_HOST="$${DOCKER_HOST:-unix:///var/run/docker.sock}"
      ROUTER_CONTAINER_NAME="$${ROUTER_CONTAINER_NAME:-warp_router}"
      DOCKER_NETWORK_NAME="$${DOCKER_NETWORK_NAME:-warp-nat-net}"
      WARP_CONTAINER_NAME="$${WARP_CONTAINER_NAME:-warp-nat-gateway}"
      HOST_VETH_IP="$${HOST_VETH_IP:-169.254.100.1}"
      CONT_VETH_IP="$${CONT_VETH_IP:-169.254.100.2}"
      ROUTING_TABLE="$${ROUTING_TABLE:-warp-nat-routing}"
      VETH_HOST="$${VETH_HOST:-veth-warp}" 

      # VETH_CONT is derived from VETH_HOST
      VETH_CONT="$${VETH_HOST#veth-}-nat-cont"
      DOCKER="docker -H $$DOCKER_HOST"
      DEFAULT_DOCKER_NETWORK_NAME="warp-nat-net"

      # Pick a free routing table id dynamically (start at 110)
      pick_table_id() {
          local id=110
          while grep -q "^$$id " /etc/iproute2/rt_tables 2>/dev/null; do
              id=$$((id+1))
          done
          echo $$id
      }

      # Get existing routing table ID if name exists, else pick new and add
      if grep -q " $$ROUTING_TABLE$$" /etc/iproute2/rt_tables 2>/dev/null; then
          ROUTING_TABLE_ID=$$(awk "/ $$ROUTING_TABLE\$$/ {print \$$1}" /etc/iproute2/rt_tables)
          echo "Routing table id acquired: \`$$ROUTING_TABLE_ID\`"
      else
          ROUTING_TABLE_ID=$$(pick_table_id)
          echo "$$ROUTING_TABLE_ID $$ROUTING_TABLE" >> /etc/iproute2/rt_tables
      fi

      if docker ps -a --format '{{.Names}}' | grep -w "$${ROUTER_CONTAINER_NAME}" >/dev/null 2>&1; then
          echo "Container '$${ROUTER_CONTAINER_NAME}' exists."
          # Determine docker network name and subnet dynamically if not provided
          if [[ -z "$${DOCKER_NETWORK_NAME:-}" ]]; then
              echo "Trying to find the network that $${ROUTER_CONTAINER_NAME} is connected to..."
              warp_router_networks="$$($$DOCKER inspect -f '{{range $$k,$$v := .NetworkSettings.Networks}}{{printf \"%s\n\" $$k}}{{end}}' $${ROUTER_CONTAINER_NAME} 2>/dev/null || true)"
              if [[ -n "$$warp_router_networks" ]]; then
                  # Use the first network found
                  DOCKER_NETWORK_NAME="$${warp_router_networks%%$$'\n'*}"
                  echo "DOCKER_NETWORK_NAME: '$$DOCKER_NETWORK_NAME'"
              else
                  echo "DOCKER_NETWORK_NAME: not found nor set"
              fi
          fi
      fi

      # If not set, fallback to default
      if [[ -z "$${DOCKER_NETWORK_NAME:-}" ]]; then
          echo "DOCKER_NETWORK_NAME: \`$$DOCKER_NETWORK_NAME\` not set, using default \`$$DEFAULT_DOCKER_NETWORK_NAME\`"
          DOCKER_NETWORK_NAME="$$DEFAULT_DOCKER_NETWORK_NAME"
      fi

      # Create docker network if it doesn't exist
      if $$DOCKER network inspect $$DOCKER_NETWORK_NAME --format '{{.Name}}' | grep -q "^$$DOCKER_NETWORK_NAME$$"; then
          echo "Docker network \`$$DOCKER_NETWORK_NAME\` already exists, recreating it"
          RECREATED_WARP_NETWORK=1

          # Store original gw_priority for each container
          CONTAINERS_USING_WARP_NETWORK=$$($$DOCKER network inspect $$DOCKER_NETWORK_NAME -f '{{range $$k, $$v := .Containers}}{{$$v.Name}} {{end}}')
          CONTAINERS_USING_WARP_NETWORK_COUNT=$$(echo "$$CONTAINERS_USING_WARP_NETWORK" | wc -w)
          CONTAINER_INDEX=0

          # Map: container_name:gw_priority
          declare -A ORIGINAL_GW_PRIORITY

          # Get original gw_priority for each container
          for container in $$CONTAINERS_USING_WARP_NETWORK; do
              # Get the container's network info as JSON
              set +x
              container_json="$$($$DOCKER inspect "$$container" 2>/dev/null)"
              set -x
              # Extract the gw_priority for this network
              gw_priority=$$(echo "$$container_json" | jq -r --arg net "$$DOCKER_NETWORK_NAME" '.[0].NetworkSettings.Networks[$$net].GwPriority // empty')
              ORIGINAL_GW_PRIORITY["$$container"]="$$gw_priority"
          done

          for container in $$CONTAINERS_USING_WARP_NETWORK; do
              CONTAINER_INDEX=$$((CONTAINER_INDEX + 1))
              echo "Disconnecting \`$$container\` from \`$$DOCKER_NETWORK_NAME\` ($$CONTAINER_INDEX out of $$CONTAINERS_USING_WARP_NETWORK_COUNT )"
              $$DOCKER network disconnect $$DOCKER_NETWORK_NAME "$$container"
          done

          $$DOCKER network rm $$DOCKER_NETWORK_NAME 2>/dev/null || true
      fi

      echo "Creating docker network \`$$DOCKER_NETWORK_NAME\`"
      $$DOCKER network create --driver=bridge \
          --attachable \
          -o com.docker.network.bridge.name=br_$$DOCKER_NETWORK_NAME \
          -o com.docker.network.bridge.enable_ip_masquerade=false \
          $$DOCKER_NETWORK_NAME --subnet=$${WARP_NAT_NET_SUBNET:-10.0.2.0/24} --gateway=$${WARP_NAT_NET_GATEWAY:-10.0.2.1} || true

      if [[ -n "$${RECREATED_WARP_NETWORK:-}" ]]; then
          echo "Connecting containers to \`$$DOCKER_NETWORK_NAME\`"
          CONTAINER_INDEX=0
          for container in $$CONTAINERS_USING_WARP_NETWORK; do
              CONTAINER_INDEX=$$((CONTAINER_INDEX + 1))
              # Use original gw_priority if available, else fallback to 0x7FFFFFFFFFFFFFFF
              gw_priority="$${ORIGINAL_GW_PRIORITY[$$container]}"
              if [[ -n "$$gw_priority" && "$$gw_priority" != "null" ]]; then
                  echo "Connecting \`$$container\` to \`$$DOCKER_NETWORK_NAME\` with original gw_priority=$$gw_priority ($$CONTAINER_INDEX out of $$CONTAINERS_USING_WARP_NETWORK_COUNT )"
                  $$DOCKER network connect --gw-priority "$$gw_priority" "$$DOCKER_NETWORK_NAME" "$$container" || true
              else
                  echo "Connecting \`$$container\` to \`$$DOCKER_NETWORK_NAME\` with default gw_priority ($$CONTAINER_INDEX out of $$CONTAINERS_USING_WARP_NETWORK_COUNT )"
                  $$DOCKER network connect --gw-priority 0x7FFFFFFFFFFFFFFF "$$DOCKER_NETWORK_NAME" "$$container" || true
              fi
          done
      fi

      # Get stack name from eithe warp_router, or if script was ran on host, get from warp-nat-gateway
      STACK_NAME="$$(
          $$DOCKER inspect -f '{{ index .Config.Labels "com.docker.compose.project" }}' "$$ROUTER_CONTAINER_NAME" 2>/dev/null \
          || $$DOCKER inspect -f '{{ index .Config.Labels "com.docker.compose.project" }}' "$$WARP_CONTAINER_NAME" 2>/dev/null
      )"
      # Strip project prefix (handles both prefixed and non-prefixed names)
      # Pattern includes trailing '_' for Compose-managed networks
      BASE_NETWORK_NAME="$${DOCKER_NETWORK_NAME#$$STACK_NAME_}"
      STACK_NETWORK_NAME="$$STACK_NAME_$${BASE_NETWORK_NAME:-$$DOCKER_NETWORK_NAME}"
      BRIDGE_NAME="br_$${BASE_NETWORK_NAME:-$$DOCKER_NETWORK_NAME}"

      # Dynamically get DOCKER_NET from network
      DOCKER_NET="$$(
          (
              $$DOCKER network inspect -f '{{(index .IPAM.Config 0).Subnet}}' "$$STACK_NETWORK_NAME" 2>/dev/null \
              || $$DOCKER network inspect -f '{{(index .IPAM.Config 0).Subnet}}' "$$BASE_NETWORK_NAME" 2>/dev/null
          ) | tr -d '[:space:]'
      )"
      if [[ -z "$$DOCKER_NET" ]]; then
          echo "Error: \`\$$DOCKER_NET\` not found"
          exit 1
      fi

      # Remove existing veth if present (handles restarts/crashes)
      ip link del "$$VETH_HOST" 2>/dev/null || true

      # Create veth pair
      ip link add "$$VETH_HOST" type veth peer name "$$VETH_CONT"

      warp_pid="$$($$DOCKER inspect -f '{{.State.Pid}}' $$WARP_CONTAINER_NAME || echo \"\")"
      if [[ -z "$$warp_pid" ]]; then
          echo ""
          echo "Error: \`$$WARP_CONTAINER_NAME\` container not found"
          echo "\`$$WARP_CONTAINER_NAME\` container not found" >> /var/log/warp-nat-routing.log
          echo ""
          exit 1
      fi

      if [[ ! -e "/proc/$$warp_pid/ns/net" ]]; then
          echo ""
          echo "Error: \`$$WARP_CONTAINER_NAME\` container network namespace not ready"
          echo "\`$$WARP_CONTAINER_NAME\` container network namespace not ready" >> /var/log/warp-nat-routing.log
          echo ""
          exit 1
      fi

      # Clean orphan ip rules for this routing table
      ip rule show | grep "lookup $$ROUTING_TABLE" | while read -r line; do
          from_cidr=$$(echo "$$line" | awk '{for (i=1;i<=NF;i++) if ($$i=="from") print $$(i+1)}')
          if [[ -z "$$from_cidr" ]]; then continue; fi
          if [[ "$$from_cidr" == "$$DOCKER_NET" ]]; then continue; fi
          route_line=$$(ip route show exact "$$from_cidr" 2>/dev/null)
          if [[ -z "$$route_line" ]]; then
              echo "Removing orphan rule for non-existing network: $$from_cidr"
              ip rule del from "$$from_cidr" table "$$ROUTING_TABLE" 2>/dev/null || true
              continue
          fi
          dev=$$(echo "$$route_line" | awk '{print $$3}')
          state=$$(ip link show "$$dev" 2>/dev/null | grep -E -o 'state \K\w+' || echo "DOWN")
          if [[ "$$state" != "UP" ]]; then
              echo "Removing orphan rule for down interface $$dev: $$from_cidr"
              ip rule del from "$$from_cidr" table "$$ROUTING_TABLE" 2>/dev/null || true
          fi
      done

      # Clean orphan NAT rules on host
      iptables -t nat -S POSTROUTING | grep -- '-j MASQUERADE' | grep ' ! -d ' | while read -r rule; do
          s_net=$$(echo "$$rule" | sed -n 's/.*-s \([^ ]*\) .*/\1/p')
          d_net=$$(echo "$$rule" | sed -n 's/.*! -d \([^ ]*\) .*/\1/p')
          if [[ "$$s_net" != "$$d_net" || -z "$$s_net" ]]; then continue; fi
          if [[ "$$s_net" == "$$DOCKER_NET" ]]; then continue; fi
          route_line=$$(ip route show exact "$$s_net" 2>/dev/null)
          if [[ -z "$$route_line" ]]; then
              echo "Removing orphan NAT rule for non-existing network: $$s_net"
              del_rule=$$(echo "$$rule" | sed 's/^-A/-D/')
              iptables -t nat $$del_rule 2>/dev/null || true
              continue
          fi
          dev=$$(echo "$$route_line" | awk '{print $$3}')
          state=$$(ip link show "$$dev" 2>/dev/null | grep -E -o 'state \K\w+' || echo "DOWN")
          if [[ "$$state" != "UP" ]]; then
              echo "Removing orphan NAT rule for down interface $$dev: $$s_net"
              del_rule=$$(echo "$$rule" | sed 's/^-A/-D/')
              iptables -t nat $$del_rule 2>/dev/null || true
          fi
      done

      # Clean orphan NAT rules inside warp container
      nsenter -t "$$warp_pid" -n iptables -t nat -S POSTROUTING | grep -- '-j MASQUERADE' | while read -r rule; do
          s_net=$$(echo "$$rule" | sed -n 's/.*-s \([^ ]*\) -j MASQUERADE.*/\1/p')
          if [[ -z "$$s_net" ]]; then continue; fi
          if [[ "$$s_net" == "$$DOCKER_NET" ]]; then continue; fi
          route_line=$$(ip route show exact "$$s_net" 2>/dev/null)
          if [[ -z "$$route_line" ]]; then
              echo "Removing orphan NAT rule inside warp for non-existing network: $$s_net"
              del_rule=$$(echo "$$rule" | sed 's/^-A/-D/')
              nsenter -t "$$warp_pid" -n iptables -t nat $$del_rule 2>/dev/null || true
              continue
          fi
          dev=$$(echo "$$route_line" | awk '{print $$3}')
          state=$$(ip link show "$$dev" 2>/dev/null | grep -E -o 'state \K\w+' || echo "DOWN")
          if [[ "$$state" != "UP" ]]; then
              echo "Removing orphan NAT rule inside warp for down interface $$dev: $$s_net"
              del_rule=$$(echo "$$rule" | sed 's/^-A/-D/')
              nsenter -t "$$warp_pid" -n iptables -t nat $$del_rule 2>/dev/null || true
          fi
      done

      # Set up cleanup function
      cleanup() {
          echo "âš ï¸ Error occurred. Rolling back..."

          # Remove host veth
          remove_host_veth_cmd="ip link del $$VETH_HOST"
          echo "Removing host veth: '$$remove_host_veth_cmd'"
          eval "$$remove_host_veth_cmd 2>/dev/null || true"

          # Remove ip rules
          remove_ip_rules_cmd="ip rule del from $$DOCKER_NET table $$ROUTING_TABLE"
          echo "Removing ip rules: '$$remove_ip_rules_cmd'"
          eval "$$remove_ip_rules_cmd 2>/dev/null || true"

          # Flush routing table if exists
          if ip route show table "$$ROUTING_TABLE" >/dev/null 2>&1; then
              flush_routing_table_cmd="ip route flush table $$ROUTING_TABLE"
              echo "Flushing routing table: '$$flush_routing_table_cmd'"
              eval "$$flush_routing_table_cmd"
          fi

          # Remove NAT rules on host
          remove_nat_rules_on_host_cmd="iptables -t nat -D POSTROUTING -s $$DOCKER_NET ! -d $$DOCKER_NET -j MASQUERADE"
          echo "Removing NAT rules on host: '$$remove_nat_rules_on_host_cmd'"
          eval "$$remove_nat_rules_on_host_cmd 2>/dev/null || true"

          # Remove NAT rules inside warp container
          remove_nat_rules_inside_warp_cmd="nsenter -t $$warp_pid -n iptables -t nat -D POSTROUTING -s $$DOCKER_NET -j MASQUERADE"
          echo "Removing NAT rules inside warp container: '$$remove_nat_rules_inside_warp_cmd'"
          eval "$$remove_nat_rules_inside_warp_cmd 2>/dev/null || true"
      }

      # Trap any error in the critical section
      trap cleanup ERR

      # --- Critical setup section ---
      # Remove existing veth if present (handles restarts/crashes)
      ip link del "$$VETH_HOST" 2>/dev/null || true

      # Create veth pair
      ip link add "$$VETH_HOST" type veth peer name "$$VETH_CONT"

      # Move container end into warp namespace
      ip link set "$$VETH_CONT" netns "$$warp_pid"

      # Assign host end
      ip addr add "$$HOST_VETH_IP/30" dev "$$VETH_HOST"
      ip link set "$$VETH_HOST" up

      # Assign container end
      nsenter -t "$$warp_pid" -n ip addr add "$$CONT_VETH_IP/30" dev "$$VETH_CONT"
      nsenter -t "$$warp_pid" -n ip link set "$$VETH_CONT" up
      nsenter -t "$$warp_pid" -n sysctl -w net.ipv4.ip_forward=1
      #nsenter -t "$$warp_pid" -n sysctl -w net.ipv4.conf.all.rp_filter=2
      #nsenter -t "$$warp_pid" -n sysctl -w net.ipv4.conf.default.rp_filter=2

      # NAT inside warp (add if not exists)
      nsenter -t "$$warp_pid" -n iptables -t nat -C POSTROUTING -s "$$DOCKER_NET" -j MASQUERADE 2>/dev/null || \
      nsenter -t "$$warp_pid" -n iptables -t nat -A POSTROUTING -s "$$DOCKER_NET" -j MASQUERADE

      # Routing rules (del if exists, then add)
      ip rule del from "$$DOCKER_NET" table "$$ROUTING_TABLE" 2>/dev/null || true
      ip rule add from "$$DOCKER_NET" table "$$ROUTING_TABLE"

      # Ensure routing table exists before flushing
      if ip route show table "$$ROUTING_TABLE" >/dev/null 2>&1; then
          ip route flush table "$$ROUTING_TABLE"
      fi
      echo "Using bridge device: \`$$BRIDGE_NAME\`"

      # Default route(s)
      ip route add "$$DOCKER_NET" dev "$$BRIDGE_NAME" table "$$ROUTING_TABLE"  # Add network route using stripped bridge name
      ip route add default via "$$CONT_VETH_IP" dev "$$VETH_HOST" table "$$ROUTING_TABLE"  # Add default route

      # NAT on host (add if not exists)
      iptables -t nat -C POSTROUTING -s "$$DOCKER_NET" ! -d "$$DOCKER_NET" -j MASQUERADE 2>/dev/null || \
      iptables -t nat -A POSTROUTING -s "$$DOCKER_NET" ! -d "$$DOCKER_NET" -j MASQUERADE

      # Confirmation
      echo "âœ… Warp setup complete"
      echo " Network: \`$$DOCKER_NETWORK_NAME\`"
      echo " Veth host: \`$$VETH_HOST\` ($$HOST_VETH_IP)"
      echo " Veth cont: \`$$VETH_CONT\` ($$CONT_VETH_IP)"
      echo " Docker net: \`$$DOCKER_NET\`"
      echo " Routing table: \`$$ROUTING_TABLE\` ($$ROUTING_TABLE_ID)"

  warp-monitor.sh:
    content: |
      #!/usr/bin/env bash
      set -euo pipefail

      # Configurable via env
      DOCKER_CMD="$${DOCKER_CMD:-docker -H $${DOCKER_HOST:-unix:///var/run/docker.sock}}"
      CHECK_IMAGE="$${CHECK_IMAGE:-curlimages/curl:latest}"   # image that includes curl
      NETWORK="$${NETWORK:-warp-nat-net}"
      SLEEP_INTERVAL="$${SLEEP_INTERVAL:-5}"                  # seconds between checks

      # Healthcheck command to run inside the ephemeral container.
      # This mirrors your warp-healthcheck logic: exit 0 when WARP active, nonzero otherwise.
      HEALTHCHECK_INSIDE='sh -c "if curl -s --max-time 4 https://cloudflare.com/cdn-cgi/trace | grep -qE \"^warp=on|warp=plus$$\"; then echo WARP_OK && exit 0; else echo WARP_NOT_OK && exit 1; fi"'

      echo "warp-monitor: checking WARP via ephemeral container on network '$${NETWORK}'."
      echo "Using image: $${CHECK_IMAGE}"
      prev_ok=1  # assume healthy initially so we don't run setup at startup

      while true; do
        echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] running health probe..."
        if $${DOCKER_CMD} run --rm --network "$${NETWORK}" --entrypoint sh "$${CHECK_IMAGE}" -c "$${HEALTHCHECK_INSIDE}"; then
          # check succeeded
          if [[ "$${prev_ok}" -eq 0 ]]; then
            echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] health probe recovered -> marking healthy"
          fi
          prev_ok=1
        else
          echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] health probe failed"
          # Only run the setup if this is a transition from healthy -> unhealthy
          if [[ "$${prev_ok}" -eq 1 ]]; then
            echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] detected healthy->unhealthy transition; running /usr/local/bin/warp-nat-setup.sh"
            # Run setup, but do not let its failure kill the monitor. Log failures.
            if /usr/local/bin/warp-nat-setup.sh; then
              echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] warp-nat-setup.sh completed"
            else
              echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] warp-nat-setup.sh failed (exit nonzero)."
            fi
            # mark as unhealthy until probe says otherwise
            prev_ok=0
            # Wait a little before probing again to avoid tight loops
            sleep "$${SLEEP_INTERVAL}"
            # continue to next iteration (which will probe again and wait for recovery)
          else
            echo "[$$(date -u +'%Y-%m-%dT%H:%M:%SZ')] still unhealthy; skipping additional setup runs"
          fi
        fi

        sleep "$${SLEEP_INTERVAL}"
      done

services:
  warp-nat-gateway:
    # ðŸ”¹ðŸ”¹ WARP in Docker (with NAT)ðŸ”¹
    image: docker.io/caomingjun/warp:latest
    container_name: warp-nat-gateway
    hostname: warp-nat-gateway
    extra_hosts:
      - host.docker.internal:host-gateway
    expose:
      - ${GOST_SOCKS5_PORT:-1080}  # SOCKS5 proxy port
    # add removed rule back (https://github.com/opencontainers/runc/pull/3468)
    device_cgroup_rules:
      - 'c 10:200 rwm'
    cap_add:
      # Docker already have them, these are for podman users
      - MKNOD
      - AUDIT_WRITE
      # additional required cap for warp, both for podman and docker
      - NET_ADMIN
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
      - net.ipv4.conf.all.src_valid_mark=1
      - net.ipv4.ip_forward=1
      - net.ipv6.conf.all.forwarding=1
      - net.ipv6.conf.all.accept_ra=2
    volumes:
      - warp-config-data:/var/lib/cloudflare-warp
    environment:
      # If set, will add checks for host connectivity into healthchecks and automatically fix it if necessary.
      # See https://github.com/cmj2002/warp-docker/blob/main/docs/host-connectivity.md for more information.
      BETA_FIX_HOST_CONNECTIVITY: false
      # The arguments passed to GOST. The default is -L :1080, which means to listen on port 1080 in the container at the same time through HTTP and SOCKS5 protocols.
      # If you want to have UDP support or use advanced features provided by other protocols, you can modify this parameter. For more information, refer to https://v2.gost.run/en/.
      # If you modify the port number, ensure you modify the `ports:` section above.
      GOST_ARGS: ${GOST_ARGS:--L :${GOST_SOCKS5_PORT:-1080}}
      # If set, will register consumer account (WARP or WARP+, in contrast to Zero Trust) even when mdm.xml exists.
      # You usually don't need this, as mdm.xml are usually used for Zero Trust.
      # However, some users may want to adjust advanced settings in mdm.xml while still using consumer account.
      #REGISTER_WHEN_MDM_EXISTS: ""
      # If set, will work as warp mode and turn NAT on.
      # You can route L3 traffic through warp-docker to Warp.
      # See https://github.com/cmj2002/warp-docker/blob/main/docs/nat-gateway.md for more information.
      WARP_ENABLE_NAT: false
      # The license key of the WARP client, which is optional.
      # If you have subscribed to WARP+ service, you can fill in the key in this environment variable.
      # If you have not subscribed to WARP+ service, you can ignore this environment variable.
      WARP_LICENSE_KEY: $WARP_LICENSE_KEY
      # The time to wait for the WARP daemon to start, in seconds.
      # If the time is too short, it may cause the WARP daemon to not start before using the proxy, resulting in the proxy not working properly.
      # If the time is too long, it may cause the container to take too long to start. If your server has poor performance, you can increase this value appropriately.
      WARP_SLEEP: 2  # The default is 2 seconds.
    healthcheck: &warp-healthcheck
      test: [
        "CMD-SHELL",
        "sh -c \"if curl -s https://cloudflare.com/cdn-cgi/trace | grep -qE '^warp=on|warp=plus$$'; then echo \\\"Cloudflare WARP is active.\\\" && exit 0; else echo \\\"Cloudflare WARP is not active.\\\" && exit 1; fi\""
      ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: always

  warp_router:
    depends_on:
      warp-nat-gateway:
        condition: service_healthy
    build:
      dockerfile_inline: |
        FROM alpine:latest
        RUN apk update && apk add \
            bash bc docker-cli ipcalc iproute2 iptables jq util-linux && \
            rm -rf /var/cache/apk/*
    container_name: warp_router
    # run the monitor wrapper (it will run warp-nat-setup.sh ONLY when this container's health becomes 'unhealthy')
    command:
      - /bin/bash
      - /usr/local/bin/warp-monitor.sh
    privileged: true
# unsure if any of these are required or not
#    cap_add:
#      - NET_ADMIN
#      - NET_RAW
#      - SYS_ADMIN
    network_mode: host
    configs:
      - source: warp-nat-setup.sh
        target: /usr/local/bin/warp-nat-setup.sh
        mode: 700
      - source: warp-monitor.sh
        target: /usr/local/bin/warp-monitor.sh
        mode: 700
    volumes:
      - ${DOCKER_SOCKET:-/var/run/docker.sock}:/var/run/docker.sock:rw
      - /etc/iproute2/rt_tables:/etc/iproute2/rt_tables:rw
      - /proc:/proc:rw
    environment:
      DOCKER_NETWORK_NAME: ${DOCKER_NETWORK_NAME:-warp-nat-net}
      WARP_CONTAINER_NAME: ${WARP_CONTAINER_NAME:-warp-nat-gateway}
      HOST_VETH_IP: ${HOST_VETH_IP:-169.254.100.1}
      CONT_VETH_IP: ${CONT_VETH_IP:-169.254.100.2}
      ROUTING_TABLE: ${ROUTING_TABLE:-warp-nat-routing}
      VETH_HOST: ${VETH_HOST:-veth-warp}  # 9 character maximum
      CONTAINER_NAME: warp_router
    restart: always

  ip-checker-warp:
    # ðŸ”¹ðŸ”¹ IP Checker WARP ðŸ”¹ðŸ”¹
    # This is a service that checks the IP address of the container.
    # It uses the WARP network interface.
    image: docker.io/alpine:latest
    container_name: ip-checker-warp
    networks:
      - warp-nat-net
    command:
      - /bin/sh
      - -c
      - |
        apk add --no-cache curl ipcalc
        while true; do echo "$(date): $(curl -s --max-time 4 ifconfig.me)"; sleep 5; done
    # End of Selection
    healthcheck: *warp-healthcheck
    restart: always
