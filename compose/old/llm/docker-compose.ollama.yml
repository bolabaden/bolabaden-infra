x-common-env: &common-env
  TZ: ${TZ:-America/Chicago} # Your Timezone
  PUID: ${PUID:-1002}
  PGID: ${PGID:-988}
  UMASK: ${UMASK:-002}

x-common-uidgid: &common-uidgid
  user: ${PUID:-1002}:${PGID:-988}

x-resource-limits: &resource-limits
  cpu_shares: 1024
  labels:
    autoheal: "true"

x-common-deploy: &common-deploy
  restart_policy:
    condition: on-failure
    delay: 5s
    window: 120s
  labels:
    autoheal: "true"
    swarm.autoscaler: "true"

x-swarm-resource-limits: &swarm-resource-limits
  resources:
    limits:
      cpus: "0.10"
      memory: 512M

x-swarm-preferences-worker-priority: &swarm-preferences-worker-priority
  placement:
    preferences:
      - spread: node.labels.worker_priority

x-swarm-constraints-worker-only: &swarm-constraints-worker-only
  placement:
    constraints:
      - node.role == worker

x-swarm-constraints-manager-only: &swarm-constraints-manager-only
  placement:
    constraints:
      - node.role == manager

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - ${OLLAMA_PORT:-11434}:11434
    volumes:
      - ${CONFIG_PATH:-./volumes}/ollama/code:/code
      - ${CONFIG_PATH:-./volumes}/ollama/ollama:/root/.ollama
    container_name: ollama
    <<: [*common-uidgid, *common-logging, *resource-limits]
    pull_policy: always
    tty: true
    restart: always
    environment:
      <<: *common-env
      OLLAMA_KEEP_ALIVE: ${OLLAMA_KEEP_ALIVE:-24h}
      OLLAMA_HOST: ${OLLAMA_HOST:-0.0.0.0}
    networks:
      - infranet
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
  #    resources:
  #      reservations:
  #          devices:
  #            - driver: nvidia
  #              count: all
  #              capabilities: [gpu]

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    hostname: open-webui
    <<: [*common-uidgid, *common-logging, *resource-limits]
    networks:
      - infranet
    volumes:
      - ${CONFIG_PATH:-./volumes}/open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - ${OPEN_WEBUI_PORT:-8073}:8080
    environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
      <<: *common-env
      OLLAMA_BASE_URLS: http://ollama:${OLLAMA_PORT:-11434}
      ENV: ${ENV:-dev}
      WEBUI_AUTH: ${WEBUI_AUTH:-false}
      WEBUI_NAME: ${WEBUI_NAME:-valiantlynx AI}
      WEBUI_URL: http://open-webui.$DOMAIN:${OPEN_WEBUI_PORT:-8073}
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY:?WEBUI_SECRET_KEY is not set}
    deploy:
      <<: [*common-deploy, *swarm-resource-limits]
    restart: always
